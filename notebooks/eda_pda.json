{"paragraphs":[{"text":"import pyspark.sql.functions as F\nfrom pyspark.sql import SparkSession\nfrom pyspark.ml import Pipeline\nfrom pyspark.sql.window import Window\n\nfrom pyspark.ml.classification import GBTClassifier, LinearSVC, MultilayerPerceptronClassifier\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator as BCE\nfrom pyspark.ml import PCA\n\nfrom pyspark.sql.types import StructType,StructField, StringType, DoubleType\n\nspark = SparkSession.builder\\\n    .appName(\"BDT Project\")\\\n    .master(\"local[*]\")\\\n    .config(\"hive.metastore.uris\", \"thrift://sandbox-hdp.hortonworks.com:9083\")\\\n    .config(\"spark.sql.catalogImplementation\",\"hive\")\\\n    .config(\"spark.sql.avro.compression.codec\", \"snappy\")\\\n    .config(\"spark.jars\", \"file:///usr/hdp/current/hive-client/lib/hive-metastore-1.2.1000.2.6.5.0-292.jar,file:///usr/hdp/current/hive-client/lib/hive-exec-1.2.1000.2.6.5.0-292.jar\")\\\n    .config(\"spark.jars.packages\",\"org.apache.spark:spark-avro_2.12:3.0.3\")\\\n    .config(\"spark.driver.memory\", \"1g\")\\\n    .enableHiveSupport()\\\n    .getOrCreate()\n\nsc = spark.sparkContext\n\nfor n in spark.catalog.listDatabases():\n    print(n.name)\n\nfor n in spark.catalog.listTables(\"quantdb\"):\n    print(n.name)\n\n\ndata = spark.read.format(\"avro\").table('quantdb.snapshots')\n","user":"anonymous","dateUpdated":"2023-05-12T08:53:08+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python","tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"... ... ... ... ... ... ... ... ... ... ... ... default\nfoodmart\nquantdb\n... ... binance_btcusdt_5_100_timestamp_extract\nmoving_avg\nsnapshots\n"}]},"apps":[],"jobName":"paragraph_1683741443049_131260918","id":"20230510-175723_14187414","dateCreated":"2023-05-10T17:57:23+0000","dateStarted":"2023-05-12T07:38:59+0000","dateFinished":"2023-05-12T07:39:01+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:270"},{"text":"#=================definition of constants============\n\nTOTAL_LEVELS = 5\nLOOK_FWD = 80\n","user":"anonymous","dateUpdated":"2023-05-12T07:38:59+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python","tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1683755998548_-1813226462","id":"20230510-215958_1174333052","dateCreated":"2023-05-10T21:59:58+0000","dateStarted":"2023-05-12T07:38:59+0000","dateFinished":"2023-05-12T07:39:01+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:271"},{"text":"\nfeatures_for_training = [\n    \"bid_level_1_price\",\n    \"bid_level_2_price\",\n    \"bid_level_3_price\",\n    \"bid_level_4_price\",\n    \"bid_level_5_price\",\n    \n    \"ask_level_1_price\",\n    \"ask_level_2_price\",\n    \"ask_level_3_price\",\n    \"ask_level_4_price\",\n    \"ask_level_5_price\",\n    \n    \"bid_level_1_quantity\",\n    \"bid_level_2_quantity\",\n    \"bid_level_3_quantity\",\n    \"bid_level_4_quantity\",\n    \"bid_level_5_quantity\",\n    \n    \"ask_level_1_quantity\",\n    \"ask_level_2_quantity\",\n    \"ask_level_3_quantity\",\n    \"ask_level_4_quantity\",\n    \"ask_level_5_quantity\",\n    ]","user":"anonymous","dateUpdated":"2023-05-12T07:38:59+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python","tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1683827636650_-993073809","id":"20230511-175356_1339522079","dateCreated":"2023-05-11T17:53:56+0000","dateStarted":"2023-05-12T07:39:01+0000","dateFinished":"2023-05-12T07:39:01+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:272"},{"text":"\n\n#================feature extraction===================\n\n\ndata = spark.read\\\n    .format(\"avro\")\\\n    .table('quantdb.snapshots')\\\n    .sort(\"tstamp\")\n    \n# data = spark.sql('''SELECT *, ((bid_level_1_price + ask_level_1_price) / 2) as mid_price FROM quantdb.snapshots''')\n\n# generating mid price value\ndata = data\\\n    .withColumn(\n        \"mid_price\", \n        (data.bid_level_1_price + data.ask_level_1_price) / 2)\nfeatures_for_training.append(\"mid_price\")\n\n# generating price level diffs\nfor level in range(TOTAL_LEVELS):\n    name = \"level_{}_diff\".format(level+1)\n    features_for_training.append(name)\n    data = data\\\n        .withColumn(\n            name, \n            (data[\"ask_level_{}_price\".format(level+1)] + data[\"bid_level_{}_price\".format(level+1)]))\n\n\n# generating diff between subsequent levels for asks and bids\nfor level in range(TOTAL_LEVELS - 1):  \n    name = \"ask_level_{}_price - ask_level_{}_price\".format(level+2, level+1)\n    features_for_training.append(name)\n    data = data\\\n        .withColumn(\n            name, \n            (data[\"ask_level_{}_price\".format(level+2)] - data[\"ask_level_{}_price\".format(level+1)]))\n    \n    name = \"bid_level_{}_price - bid_level_{}_price\".format(level+1, level+2)\n    features_for_training.append(name)\n    data = data\\\n        .withColumn(\n            name, \n            (data[\"bid_level_{}_price\".format(level+1)] - data[\"bid_level_{}_price\".format(level+2)]))\n\n    \n# generating diff between level 1 price and other levels for bids and asks\nfor level in range(1, TOTAL_LEVELS):\n    name = \"ask_level_{}_price - ask_level_1_price\".format(level+1)\n    features_for_training.append(name)\n    data = data\\\n        .withColumn(\n            name, \n            (data[\"ask_level_{}_price\".format(level+1)] - data[\"ask_level_1_price\"]))\n    \n    name = \"bid_level_1_price - bid_level_{}_price\".format(level+1)\n    features_for_training.append(name)\n    data = data\\\n        .withColumn(\n            name, \n            (data[\"ask_level_{}_price\".format(level+1)] - data[\"ask_level_1_price\"]))\n\n# average asks price\ndata = data\\\n    .withColumn(\n        'avg_asks_price',\n        reduce(\n            add, [data[\"ask_level_{}_price\".format(level + 1)] for level in range(TOTAL_LEVELS)]\n            ) / TOTAL_LEVELS\n    )\nfeatures_for_training.append('avg_asks_price')\n\n# average asks volume\ndata = data\\\n    .withColumn(\n        'avg_asks_quantity',\n        reduce(\n            add, [data[\"ask_level_{}_quantity\".format(level + 1)] for level in range(TOTAL_LEVELS)]\n            ) / TOTAL_LEVELS\n    )\nfeatures_for_training.append('avg_asks_quantity')\n\n# average bids price\ndata = data\\\n    .withColumn(\n        'avg_bids_price',\n        reduce(\n            add, [data[\"bid_level_{}_price\".format(level + 1)] for level in range(TOTAL_LEVELS)]\n            ) / TOTAL_LEVELS\n    )\nfeatures_for_training.append('avg_bids_price')\n\n# average bids volume\ndata = data\\\n    .withColumn(\n        'avg_bids_quantity',\n        reduce(\n            add, [data[\"bid_level_{}_quantity\".format(level + 1)] for level in range(TOTAL_LEVELS)]\n            ) / TOTAL_LEVELS\n    )\nfeatures_for_training.append('avg_bids_quantity')\n\n# sum of quantity diffs among all levels\ndata = data\\\n    .withColumn(\n        'level_diff_quantity_sum',\n        reduce(\n            add, [\n                data[\"ask_level_{}_quantity\".format(level + 1)] - \n                data[\"bid_level_{}_quantity\".format(level + 1)\n                ] for level in range(TOTAL_LEVELS)]\n            )\n        )\nfeatures_for_training.append('level_diff_quantity_sum')\n\n# sum of price diffs among all levels\ndata = data\\\n    .withColumn(\n        'level_diff_price_sum',\n        reduce(\n            add, [\n                data[\"ask_level_{}_price\".format(level + 1)] - \n                data[\"bid_level_{}_price\".format(level + 1)\n                ] for level in range(TOTAL_LEVELS)]\n            )\n        )\nfeatures_for_training.append('level_diff_price_sum')\n\n# extracting the future moving mean\nw = Window.orderBy(\"tstamp\").rowsBetween(1, LOOK_FWD)\ndata_w_labels = data.withColumn(\n    \"f_price\",\n    F.avg(data.mid_price).over(w)\n    ).limit(data.count() - LOOK_FWD)\n\n# extracting the price trend label\ndata_w_labels = data_w_labels.withColumn(\n    \"label\",\n    (data_w_labels.mid_price > data_w_labels.f_price)\\\n        .cast('integer')\n    )\\\n    .drop(data_w_labels.f_price)\n\nw = Window.orderBy(\"tstamp\")\ndata_w_labels = data_w_labels.withColumn(\n    \"index\",\n    F.row_number().over(w)\n    )\n    \ndata_w_labels = data_w_labels\\\n    .where(data_w_labels.index % 3 == 0)","user":"anonymous","dateUpdated":"2023-05-12T21:49:45+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python","tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... \n[Stage 7403:>                                                     (0 + 12) / 12]\n\n[Stage 7403:====>                                                 (1 + 11) / 12]\n\n[Stage 7403:=========>                                            (2 + 10) / 12]\n\n[Stage 7403:=============>                                         (3 + 9) / 12]\n\n[Stage 7403:==================>                                    (4 + 8) / 12]\n\n[Stage 7403:======================>                                (5 + 7) / 12]\n\n[Stage 7403:================================>                      (7 + 5) / 12]\n\n[Stage 7403:=================================================>    (11 + 1) / 12]\n\n                                                                                \n"}]},"apps":[],"jobName":"paragraph_1683741850507_58105553","id":"20230510-180410_462470371","dateCreated":"2023-05-10T18:04:10+0000","dateStarted":"2023-05-12T07:39:01+0000","dateFinished":"2023-05-12T07:39:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:273"},{"text":"#================Data preprocessing===================\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import MinMaxScaler, VectorAssembler\n\nsplit_point = int(data_w_labels.count() * 0.8)\nraw_train_data = data_w_labels\\\n    .where(data_w_labels.index < split_point)\nraw_test_data = data_w_labels\\\n    .where(data_w_labels.index >= split_point)\n\n# (train_data, test_data) = data_w_labels.randomSplit([0.8, 0.2])\n\nassembler = VectorAssembler(inputCols=features_for_training, outputCol= \"features\")\nmmScaler= MinMaxScaler(inputCol = \"features\", outputCol = \"scaled_features\")   \n\npipe = Pipeline(stages = [assembler, mmScaler])\n\npipe = pipe.fit(raw_train_data)\ntrain_data = pipe.transform(raw_train_data)\ntest_data = pipe.transform(raw_test_data)","user":"anonymous","dateUpdated":"2023-05-12T09:41:41+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python","tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"23/05/12 09:41:35 WARN scheduler.TaskSetManager: Lost task 10.0 in stage 9297.0 (TID 28314, sandbox-hdp.hortonworks.com, executor driver): TaskKilled (Stage cancelled)\n23/05/12 09:41:35 WARN scheduler.TaskSetManager: Lost task 9.0 in stage 9297.0 (TID 28313, sandbox-hdp.hortonworks.com, executor driver): TaskKilled (Stage cancelled)\n23/05/12 09:41:35 WARN scheduler.TaskSetManager: Lost task 2.0 in stage 9297.0 (TID 28306, sandbox-hdp.hortonworks.com, executor driver): TaskKilled (Stage cancelled)\n... 23/05/12 09:41:41 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n\n[Stage 9298:>                                                     (0 + 12) / 12]\n\n[Stage 9298:====>                                                 (1 + 11) / 12]\n\n[Stage 9298:=========>                                            (2 + 10) / 12]\n\n[Stage 9298:=============>                                         (3 + 9) / 12]\n\n[Stage 9298:==================>                                    (4 + 8) / 12]\n\n[Stage 9298:===========================>                           (6 + 6) / 12]\n\n[Stage 9298:================================>                      (7 + 5) / 12]\n\n[Stage 9298:====================================>                  (8 + 4) / 12]\n\n                                                                                \n... ... ... 23/05/12 09:41:55 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n\n[Stage 9300:>                                                     (0 + 12) / 12]\n\n[Stage 9300:====>                                                 (1 + 11) / 12]\n\n[Stage 9300:=========>                                            (2 + 10) / 12]\n\n[Stage 9300:=============>                                         (3 + 9) / 12]\n\n[Stage 9300:==================>                                    (4 + 8) / 12]\n\n[Stage 9300:======================>                                (5 + 7) / 12]\n\n[Stage 9300:===========================>                           (6 + 6) / 12]\n\n[Stage 9300:====================================>                  (8 + 4) / 12]\n\n[Stage 9301:>                                                       (0 + 1) / 1]\n\n                                                                                \n"}]},"apps":[],"jobName":"paragraph_1683757858628_-229734094","id":"20230510-223058_845131607","dateCreated":"2023-05-10T22:30:58+0000","dateStarted":"2023-05-12T09:41:41+0000","dateFinished":"2023-05-12T09:42:08+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:274"},{"text":"from datetime import datetime\n\ndef eval_m(model, train_data, test_data, evaluator):\n    start = datetime.now()\n    _train_data = model.transform(train_data)\n    _test_data = model.transform(test_data)\n    print(\"Predict time:{}\".format((datetime.now()-start).total_seconds()))\n    out = (evaluator.evaluate(_train_data), evaluator.evaluate(_test_data))\n    print(\"Eval results RP curve train_test: {} / {}\".format(\n        out[0], \n        out[1])\n    )\n    return out","user":"anonymous","dateUpdated":"2023-05-12T09:41:43+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python","tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1683832327667_-174138049","id":"20230511-191207_993481238","dateCreated":"2023-05-11T19:12:07+0000","dateStarted":"2023-05-12T09:41:43+0000","dateFinished":"2023-05-12T09:42:08+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:275"},{"text":"#================GBTC training=================\nevaluator = BCE(rawPredictionCol='prediction', labelCol='label')\nmodel_gbt = GBTClassifier(\n    maxDepth=5, \n    maxMemoryInMB=512,\n    maxBins=64,\n    stepSize=0.05\n)\n\nprint(\"===========gbt eval=================\")\nstart = datetime.now()\nmodel_gbt = model_gbt.fit(train_data)\nprint(\"Train time:{}\".format((datetime.now()-start).total_seconds()))\nscores_gbt = eval_m(model_gbt, train_data, test_data, evaluator)\n","user":"anonymous","dateUpdated":"2023-05-12T09:41:45+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python","tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"... ... ... ... ... ... ===========gbt eval=================\n23/05/12 09:42:08 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n23/05/12 09:42:08 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n\n[Stage 9302:>                                                     (0 + 12) / 12]\n\n[Stage 9302:====>                                                 (1 + 11) / 12]\n\n[Stage 9302:=========>                                            (2 + 10) / 12]\n\n[Stage 9302:=============>                                         (3 + 9) / 12]\n\n[Stage 9302:==================>                                    (4 + 8) / 12]\n\n[Stage 9302:===========================>                           (6 + 6) / 12]\n\n[Stage 9302:================================>                      (7 + 5) / 12]\n\n[Stage 9302:=================================================>    (11 + 1) / 12]\n\n                                                                                \n23/05/12 09:42:23 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n23/05/12 09:42:23 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n\n[Stage 9303:>                                                     (0 + 12) / 12]\n\n[Stage 9303:====>                                                 (1 + 11) / 12]\n\n[Stage 9303:=========>                                            (2 + 10) / 12]\n\n[Stage 9303:=============>                                         (3 + 9) / 12]\n\n[Stage 9303:==================>                                    (4 + 8) / 12]\n\n[Stage 9303:======================>                                (5 + 7) / 12]\n\n[Stage 9303:===========================>                           (6 + 6) / 12]\n\n[Stage 9303:================================>                      (7 + 5) / 12]\n\n[Stage 9303:====================================>                  (8 + 4) / 12]\n\n                                                                                \n\n[Stage 9304:>                                                     (0 + 12) / 12]\n\n[Stage 9304:====>                                                 (1 + 11) / 12]\n\n[Stage 9304:=========>                                            (2 + 10) / 12]\n\n[Stage 9304:=============>                                         (3 + 9) / 12]\n\n[Stage 9304:==================>                                    (4 + 8) / 12]\n\n[Stage 9304:======================>                                (5 + 7) / 12]\n\n[Stage 9304:===========================>                           (6 + 6) / 12]\n\n[Stage 9304:================================>                      (7 + 5) / 12]\n\n[Stage 9304:=============================================>        (10 + 2) / 12]\n\n[Stage 9306:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9309:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9312:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9316:>                                                       (0 + 1) / 1]\n\n                                                                                \nTrain time:74.425689\nPredict time:0.124537\n23/05/12 09:43:22 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n23/05/12 09:43:22 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n\n[Stage 9714:>                                                     (0 + 12) / 12]\n\n[Stage 9714:====>                                                 (1 + 11) / 12]\n\n[Stage 9714:=========>                                            (2 + 10) / 12]\n\n[Stage 9714:=============>                                         (3 + 9) / 12]\n\n[Stage 9714:==================>                                    (4 + 8) / 12]\n\n[Stage 9714:======================>                                (5 + 7) / 12]\n\n[Stage 9714:===========================>                           (6 + 6) / 12]\n\n[Stage 9714:================================>                      (7 + 5) / 12]\n\n                                                                                \n\n[Stage 9715:>                                                     (0 + 12) / 12]\n\n[Stage 9715:====>                                                 (1 + 11) / 12]\n\n[Stage 9715:=========>                                            (2 + 10) / 12]\n\n[Stage 9715:=============>                                         (3 + 9) / 12]\n\n[Stage 9715:==================>                                    (4 + 8) / 12]\n\n[Stage 9715:===========================>                           (6 + 6) / 12]\n\n[Stage 9715:====================================>                  (8 + 4) / 12]\n\n[Stage 9717:>                                                       (0 + 1) / 1]\n\n                                                                                \n23/05/12 09:43:51 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n23/05/12 09:43:51 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n\n[Stage 9730:>                                                     (0 + 12) / 12]\n\n[Stage 9730:====>                                                 (1 + 11) / 12]\n\n[Stage 9730:=========>                                            (2 + 10) / 12]\n\n[Stage 9730:=============>                                         (3 + 9) / 12]\n\n[Stage 9730:==================>                                    (4 + 8) / 12]\n\n[Stage 9730:===========================>                           (6 + 6) / 12]\n\n[Stage 9730:================================>                      (7 + 5) / 12]\n\n[Stage 9730:=========================================>             (9 + 3) / 12]\n\n                                                                                \n\n[Stage 9731:>                                                     (0 + 12) / 12]\n\n[Stage 9731:====>                                                 (1 + 11) / 12]\n\n[Stage 9731:=========>                                            (2 + 10) / 12]\n\n[Stage 9731:=============>                                         (3 + 9) / 12]\n\n[Stage 9731:======================>                                (5 + 7) / 12]\n\n[Stage 9731:===========================>                           (6 + 6) / 12]\n\n[Stage 9731:================================>                      (7 + 5) / 12]\n\n[Stage 9731:====================================>                  (8 + 4) / 12]\n\n[Stage 9733:>                                                       (0 + 1) / 1]\n\n                                                                                \nEval results RP curve train_test: 0.692046276437 / 0.633182956804\n"}]},"apps":[],"jobName":"paragraph_1683830591432_996786958","id":"20230511-184311_1125580911","dateCreated":"2023-05-11T18:43:11+0000","dateStarted":"2023-05-12T09:42:08+0000","dateFinished":"2023-05-12T09:44:12+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:276"},{"text":"#===================feature importance save and filter=======================\n\nimportance = model_gbt.featureImportances\nfi = [(feature, float(val)) for feature, val in zip(features_for_training, importance)]\nfi_df = spark.createDataFrame(data=fi, schema=StructType([\n     StructField(\"feature\",StringType(),True),\n     StructField(\"value\",DoubleType(),True)\n    ]))\n\nfi_df.coalesce(1)\\\n    .select(\"feature\",'value')\\\n    .write\\\n    .mode(\"overwrite\")\\\n    .format(\"csv\")\\\n    .option(\"sep\", \",\")\\\n    .option(\"header\",\"true\")\\\n    .csv(\"/project/output/features_full\")\n    \nfeatures_pca = [n[0] for n in sorted(fi, key=lambda x: x[1], reverse=True)[10:]]\nfeatures_main = [n[0] for n in sorted(fi, key=lambda x: x[1], reverse=True)[:10]]","user":"anonymous","dateUpdated":"2023-05-12T09:42:08+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"... ... ... ... ... ... ... ... ... ... ... \n[Stage 9746:>                                                       (0 + 1) / 1]\n\n                                                                                \n"}]},"apps":[],"jobName":"paragraph_1683880960356_2092130227","id":"20230512-084240_1294989472","dateCreated":"2023-05-12T08:42:40+0000","dateStarted":"2023-05-12T09:42:08+0000","dateFinished":"2023-05-12T09:44:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:277"},{"text":"#=================preprocessing with PCA===================\nfrom pyspark.ml.feature import PCA\n\n# train_data = train_data.drop([\"features\", \"raw_pca_features\", \"scaled_pca_features\", \"pca_features\", \"raw_main_features\", \"scaled_main_features\"])\n\nassembler_pca = VectorAssembler(inputCols=features_pca, outputCol= \"raw_pca_features\")\nmmScaler_pca= MinMaxScaler(inputCol = \"raw_pca_features\", outputCol = \"scaled_pca_features\")   \npca = PCA(k=2, inputCol=\"scaled_pca_features\", outputCol=\"pca_features\")\n\nassembler_main = VectorAssembler(inputCols=features_main, outputCol= \"raw_main_features\")\nmmScaler_main= MinMaxScaler(inputCol = \"raw_main_features\", outputCol = \"scaled_main_features\")\n\nassembler_final = VectorAssembler(inputCols=[\"scaled_main_features\", \"pca_features\"], outputCol= \"features\")\n\npipe = Pipeline(stages = [\n    assembler_pca, \n    mmScaler_pca,\n    pca,\n    assembler_main,\n    mmScaler_main,\n    assembler_final\n    ])\n\npipe = pipe.fit(raw_train_data)\ntrain_data = pipe.transform(raw_train_data)\ntest_data = pipe.transform(raw_test_data)","user":"anonymous","dateUpdated":"2023-05-12T09:33:01+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"... ... ... ... ... ... ... ... ... 23/05/12 09:09:04 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n\n[Stage 8355:>                                                     (0 + 12) / 12]\n\n[Stage 8355:====>                                                 (1 + 11) / 12]\n\n[Stage 8355:=========>                                            (2 + 10) / 12]\n\n[Stage 8355:=============>                                         (3 + 9) / 12]\n\n[Stage 8355:==================>                                    (4 + 8) / 12]\n\n[Stage 8355:======================>                                (5 + 7) / 12]\n\n[Stage 8355:===========================>                           (6 + 6) / 12]\n\n[Stage 8355:================================>                      (7 + 5) / 12]\n\n[Stage 8355:====================================>                  (8 + 4) / 12]\n\n[Stage 8356:>                                                       (0 + 1) / 1]\n\n                                                                                \n23/05/12 09:09:23 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n\n[Stage 8357:>                                                     (0 + 12) / 12]\n\n[Stage 8357:====>                                                 (1 + 11) / 12]\n\n[Stage 8357:=========>                                            (2 + 10) / 12]\n\n[Stage 8357:=============>                                         (3 + 9) / 12]\n\n[Stage 8357:==================>                                    (4 + 8) / 12]\n\n[Stage 8357:================================>                      (7 + 5) / 12]\n\n[Stage 8357:=========================================>             (9 + 3) / 12]\n\n[Stage 8358:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 8360:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 8362:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 8364:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 8366:>                                                       (0 + 1) / 1]\n\n                                                                                \n23/05/12 09:09:52 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n\n[Stage 8367:>                                                     (0 + 12) / 12]\n\n[Stage 8367:====>                                                 (1 + 11) / 12]\n\n[Stage 8367:=========>                                            (2 + 10) / 12]\n\n[Stage 8367:=============>                                         (3 + 9) / 12]\n\n[Stage 8367:==================>                                    (4 + 8) / 12]\n\n[Stage 8367:======================>                                (5 + 7) / 12]\n\n[Stage 8367:===========================>                           (6 + 6) / 12]\n\n[Stage 8367:====================================>                  (8 + 4) / 12]\n\n[Stage 8367:=================================================>    (11 + 1) / 12]\n\n[Stage 8368:>                                                       (0 + 1) / 1]\n\n                                                                                \n23/05/12 09:10:00 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n\n[Stage 8369:>                                                     (0 + 12) / 12]\n\n[Stage 8369:====>                                                 (1 + 11) / 12]\n\n[Stage 8369:=========>                                            (2 + 10) / 12]\n\n[Stage 8369:=============>                                         (3 + 9) / 12]\n\n[Stage 8369:==================>                                    (4 + 8) / 12]\n\n[Stage 8369:===========================>                           (6 + 6) / 12]\n\n[Stage 8369:================================>                      (7 + 5) / 12]\n\n[Stage 8369:====================================>                  (8 + 4) / 12]\n\n[Stage 8370:>                                                       (0 + 1) / 1]\n\n                                                                                \n+--------------------+\n|            features|\n+--------------------+\n|[0.00240534806871...|\n|[0.00215709239149...|\n|[0.00222004718045...|\n|[0.00222004718045...|\n|[0.00885405654527...|\n|[0.00653423196345...|\n|[4.75130482708814...|\n|[0.02596825653245...|\n|[0.04859753359766...|\n|[0.06822754949077...|\n|[0.06358077336988...|\n|[0.07985636805507...|\n|[0.07751159912290...|\n|[0.05922145119103...|\n|[0.01784708875674...|\n|[0.02510945818495...|\n|[0.00272962462316...|\n|[6.98441809581956...|\n|[0.00975205315759...|\n|[0.02230381268455...|\n+--------------------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1683881570044_-176475170","id":"20230512-085250_571920801","dateCreated":"2023-05-12T08:52:50+0000","dateStarted":"2023-05-12T09:09:03+0000","dateFinished":"2023-05-12T09:10:16+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:278"},{"text":"#================GBTC training=================\nevaluator = BCE(rawPredictionCol='prediction', labelCol='label')\nmodel_gbt = GBTClassifier(\n    maxDepth=5, \n    maxMemoryInMB=512,\n    maxBins=64,\n    stepSize=0.05\n)\n\nprint(\"===========gbt eval=================\")\nstart = datetime.now()\nmodel_gbt = model_gbt.fit(train_data)\nprint(\"Train time:{}\".format((datetime.now()-start).total_seconds()))\nscores_gbt = eval_m(model_gbt, train_data, test_data, evaluator)","user":"anonymous","dateUpdated":"2023-05-12T09:16:28+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"... ... ... ... ... ... ===========gbt eval=================\n23/05/12 09:16:28 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n23/05/12 09:16:28 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n\n[Stage 8375:>                                                     (0 + 12) / 12]\n\n[Stage 8375:====>                                                 (1 + 11) / 12]\n\n[Stage 8375:=========>                                            (2 + 10) / 12]\n\n[Stage 8375:=============>                                         (3 + 9) / 12]\n\n[Stage 8375:==================>                                    (4 + 8) / 12]\n\n[Stage 8375:===========================>                           (6 + 6) / 12]\n\n[Stage 8375:================================>                      (7 + 5) / 12]\n\n[Stage 8375:=========================================>             (9 + 3) / 12]\n\n                                                                                \n23/05/12 09:16:40 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n23/05/12 09:16:40 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n\n[Stage 8376:>                                                     (0 + 12) / 12]\n\n[Stage 8376:====>                                                 (1 + 11) / 12]\n\n[Stage 8376:=========>                                            (2 + 10) / 12]\n\n[Stage 8376:=============>                                         (3 + 9) / 12]\n\n[Stage 8376:==================>                                    (4 + 8) / 12]\n\n[Stage 8376:===========================>                           (6 + 6) / 12]\n\n[Stage 8376:================================>                      (7 + 5) / 12]\n\n[Stage 8376:=============================================>        (10 + 2) / 12]\n\n                                                                                \n\n[Stage 8377:>                                                     (0 + 12) / 12]\n\n[Stage 8377:====>                                                 (1 + 11) / 12]\n\n[Stage 8377:=========>                                            (2 + 10) / 12]\n\n[Stage 8377:=============>                                         (3 + 9) / 12]\n\n[Stage 8377:==================>                                    (4 + 8) / 12]\n\n[Stage 8377:======================>                                (5 + 7) / 12]\n\n[Stage 8377:===========================>                           (6 + 6) / 12]\n\n[Stage 8377:================================>                      (7 + 5) / 12]\n\n[Stage 8377:=========================================>             (9 + 3) / 12]\n\n[Stage 8379:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 8382:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 8385:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 8389:>                                                       (0 + 1) / 1]\n\n                                                                                \nTrain time:67.265339\nPredict time:0.681221\n23/05/12 09:17:36 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n23/05/12 09:17:36 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n\n[Stage 8787:>                                                     (0 + 12) / 12]\n\n[Stage 8787:====>                                                 (1 + 11) / 12]\n\n[Stage 8787:=========>                                            (2 + 10) / 12]\n\n[Stage 8787:=============>                                         (3 + 9) / 12]\n\n[Stage 8787:==================>                                    (4 + 8) / 12]\n\n[Stage 8787:================================>                      (7 + 5) / 12]\n\n                                                                                \n\n[Stage 8788:>                                                     (0 + 12) / 12]\n\n[Stage 8788:====>                                                 (1 + 11) / 12]\n\n[Stage 8788:=========>                                            (2 + 10) / 12]\n\n[Stage 8788:=============>                                         (3 + 9) / 12]\n\n[Stage 8788:==================>                                    (4 + 8) / 12]\n\n[Stage 8788:======================>                                (5 + 7) / 12]\n\n[Stage 8788:===========================>                           (6 + 6) / 12]\n\n[Stage 8788:================================>                      (7 + 5) / 12]\n\n[Stage 8790:>                                                       (0 + 1) / 1]\n\n                                                                                \n23/05/12 09:17:55 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n23/05/12 09:17:55 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n\n[Stage 8803:>                                                     (0 + 12) / 12]\n\n[Stage 8803:====>                                                 (1 + 11) / 12]\n\n[Stage 8803:=========>                                            (2 + 10) / 12]\n\n[Stage 8803:=============>                                         (3 + 9) / 12]\n\n[Stage 8803:==================>                                    (4 + 8) / 12]\n\n[Stage 8803:======================>                                (5 + 7) / 12]\n\n[Stage 8803:================================>                      (7 + 5) / 12]\n\n                                                                                \n\n[Stage 8804:>                                                     (0 + 12) / 12]\n\n[Stage 8804:====>                                                 (1 + 11) / 12]\n\n[Stage 8804:=========>                                            (2 + 10) / 12]\n\n[Stage 8804:==================>                                    (4 + 8) / 12]\n\n[Stage 8804:======================>                                (5 + 7) / 12]\n\n[Stage 8804:===========================>                           (6 + 6) / 12]\n\n[Stage 8804:================================>                      (7 + 5) / 12]\n\n[Stage 8804:=================================================>    (11 + 1) / 12]\n\n[Stage 8806:>                                                       (0 + 1) / 1]\n\n                                                                                \nEval results RP curve train_test: 0.6813592699 / 0.633889074282\n"}]},"apps":[],"jobName":"paragraph_1683882348617_1804327659","id":"20230512-090548_649124229","dateCreated":"2023-05-12T09:05:48+0000","dateStarted":"2023-05-12T09:16:28+0000","dateFinished":"2023-05-12T09:18:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:279"},{"text":"#===================saving new feature importance====================\n\nimportance = model_gbt.featureImportances\nfi = [(feature, float(val)) for feature, val in zip(features_main + ['pca_1', 'pca_2'], importance)]\nfi_df = spark.createDataFrame(data=fi, schema=StructType([\n     StructField(\"feature\",StringType(),True),\n     StructField(\"value\",DoubleType(),True)\n    ]))\n\nfi_df.coalesce(1)\\\n    .select(\"feature\",'value')\\\n    .write\\\n    .mode(\"overwrite\")\\\n    .format(\"csv\")\\\n    .option(\"sep\", \",\")\\\n    .option(\"header\",\"true\")\\\n    .csv(\"/project/output/features_short\")\n    ","user":"anonymous","dateUpdated":"2023-05-12T09:36:23+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1683882991112_-1225448980","id":"20230512-091631_2060551859","dateCreated":"2023-05-12T09:16:31+0000","dateStarted":"2023-05-12T09:36:23+0000","dateFinished":"2023-05-12T09:36:24+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:280"},{"text":"#====================SVC training====================\nmodel_svc = LinearSVC(\n    featuresCol=\"features\",\n    maxIter=30, \n    aggregationDepth=4\n)\n\nprint(\"===========vsc eval=================\")\nstart = datetime.now()\nmodel_svc = model_svc.fit(train_data)\nprint(\"Train time:{}\".format((datetime.now()-start).total_seconds()))\nscores_svc = eval_m(model_svc, train_data, test_data, evaluator)","user":"anonymous","dateUpdated":"2023-05-12T10:56:41+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"... ... ... ... ===========vsc eval=================\n23/05/12 09:18:20 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n23/05/12 09:18:20 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n\n[Stage 8820:>                                                     (0 + 12) / 12]\n\n[Stage 8820:====>                                                 (1 + 11) / 12]\n\n[Stage 8820:=========>                                            (2 + 10) / 12]\n\n[Stage 8820:=============>                                         (3 + 9) / 12]\n\n[Stage 8820:==================>                                    (4 + 8) / 12]\n\n[Stage 8820:======================>                                (5 + 7) / 12]\n\n[Stage 8820:===========================>                           (6 + 6) / 12]\n\n[Stage 8820:================================>                      (7 + 5) / 12]\n\n[Stage 8820:====================================>                  (8 + 4) / 12]\n\n                                                                                \n23/05/12 09:18:32 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n23/05/12 09:18:32 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n\n[Stage 8821:>                                                     (0 + 12) / 12]\n\n[Stage 8821:====>                                                 (1 + 11) / 12]\n\n[Stage 8821:=========>                                            (2 + 10) / 12]\n\n[Stage 8821:=============>                                         (3 + 9) / 12]\n\n[Stage 8821:==================>                                    (4 + 8) / 12]\n\n[Stage 8821:======================>                                (5 + 7) / 12]\n\n[Stage 8821:===========================>                           (6 + 6) / 12]\n\n[Stage 8821:================================>                      (7 + 5) / 12]\n\n                                                                                \n\n[Stage 8822:>                                                     (0 + 12) / 12]\n\n[Stage 8822:====>                                                 (1 + 11) / 12]\n\n[Stage 8822:=========>                                            (2 + 10) / 12]\n\n[Stage 8822:=============>                                         (3 + 9) / 12]\n\n[Stage 8822:==================>                                    (4 + 8) / 12]\n\n[Stage 8822:======================>                                (5 + 7) / 12]\n\n[Stage 8822:================================>                      (7 + 5) / 12]\n\n[Stage 8824:>                                                       (0 + 1) / 1]\n\n                                                                                \nTrain time:49.20456\nPredict time:0.138522\n23/05/12 09:19:09 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n23/05/12 09:19:09 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n\n[Stage 9050:>                                                     (0 + 12) / 12]\n\n[Stage 9050:====>                                                 (1 + 11) / 12]\n\n[Stage 9050:=========>                                            (2 + 10) / 12]\n\n[Stage 9050:=============>                                         (3 + 9) / 12]\n\n[Stage 9050:==================>                                    (4 + 8) / 12]\n\n[Stage 9050:======================>                                (5 + 7) / 12]\n\n[Stage 9050:===========================>                           (6 + 6) / 12]\n\n[Stage 9050:================================>                      (7 + 5) / 12]\n\n                                                                                \n\n[Stage 9051:>                                                     (0 + 12) / 12]\n\n[Stage 9051:====>                                                 (1 + 11) / 12]\n\n[Stage 9051:=========>                                            (2 + 10) / 12]\n\n[Stage 9051:=============>                                         (3 + 9) / 12]\n\n[Stage 9051:==================>                                    (4 + 8) / 12]\n\n[Stage 9051:======================>                                (5 + 7) / 12]\n\n[Stage 9051:===========================>                           (6 + 6) / 12]\n\n[Stage 9051:================================>                      (7 + 5) / 12]\n\n[Stage 9051:=============================================>        (10 + 2) / 12]\n\n[Stage 9053:>                                                       (0 + 1) / 1]\n\n                                                                                \n23/05/12 09:19:41 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n23/05/12 09:19:41 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n\n[Stage 9066:>                                                     (0 + 12) / 12]\n\n[Stage 9066:====>                                                 (1 + 11) / 12]\n\n[Stage 9066:=========>                                            (2 + 10) / 12]\n\n[Stage 9066:=============>                                         (3 + 9) / 12]\n\n[Stage 9066:==================>                                    (4 + 8) / 12]\n\n[Stage 9066:===========================>                           (6 + 6) / 12]\n\n[Stage 9066:================================>                      (7 + 5) / 12]\n\n[Stage 9066:====================================>                  (8 + 4) / 12]\n\n                                                                                \n\n[Stage 9067:>                                                     (0 + 12) / 12]\n\n[Stage 9067:====>                                                 (1 + 11) / 12]\n\n[Stage 9067:=========>                                            (2 + 10) / 12]\n\n[Stage 9067:=============>                                         (3 + 9) / 12]\n\n[Stage 9067:==================>                                    (4 + 8) / 12]\n\n[Stage 9067:================================>                      (7 + 5) / 12]\n\n[Stage 9067:=========================================>             (9 + 3) / 12]\n\n[Stage 9069:>                                                       (0 + 1) / 1]\n\n                                                                                \nEval results RP curve train_test: 0.642490355754 / 0.628499509297\n"}]},"apps":[],"jobName":"paragraph_1683846849257_1170041247","id":"20230511-231409_898549189","dateCreated":"2023-05-11T23:14:09+0000","dateStarted":"2023-05-12T09:18:19+0000","dateFinished":"2023-05-12T09:20:06+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:281"},{"text":"#====================MPC training====================\nmodel_mpc = MultilayerPerceptronClassifier(\n    featuresCol=\"features\",\n    maxIter=40,\n    layers=[len(features_main) + 2, 512,128,2]\n)\n\nprint(\"===========mpc eval=================\")\nstart = datetime.now()\nmodel_mpc = model_mpc.fit(train_data)\nprint(\"Train time:{}\".format((datetime.now()-start).total_seconds()))\nscores_mpc = eval_m(model_mpc, train_data, test_data, evaluator)","user":"anonymous","dateUpdated":"2023-05-12T10:56:59+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"... ... ... ... ===========mpc eval=================\n23/05/12 09:22:27 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n23/05/12 09:22:27 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n\n[Stage 9088:>                                                     (0 + 12) / 12]\n\n[Stage 9088:====>                                                 (1 + 11) / 12]\n\n[Stage 9088:=========>                                            (2 + 10) / 12]\n\n[Stage 9088:=============>                                         (3 + 9) / 12]\n\n[Stage 9088:==================>                                    (4 + 8) / 12]\n\n[Stage 9088:===========================>                           (6 + 6) / 12]\n\n[Stage 9088:================================>                      (7 + 5) / 12]\n\n                                                                                \n23/05/12 09:22:39 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n23/05/12 09:22:39 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n\n[Stage 9089:>                                                     (0 + 12) / 12]\n\n[Stage 9089:====>                                                 (1 + 11) / 12]\n\n[Stage 9089:=========>                                            (2 + 10) / 12]\n\n[Stage 9089:=============>                                         (3 + 9) / 12]\n\n[Stage 9089:==================>                                    (4 + 8) / 12]\n\n[Stage 9089:======================>                                (5 + 7) / 12]\n\n[Stage 9089:===========================>                           (6 + 6) / 12]\n\n[Stage 9089:================================>                      (7 + 5) / 12]\n\n[Stage 9089:=============================================>        (10 + 2) / 12]\n\n                                                                                \n\n[Stage 9090:>                                                     (0 + 12) / 12]\n\n[Stage 9090:====>                                                 (1 + 11) / 12]\n\n[Stage 9090:=========>                                            (2 + 10) / 12]\n\n[Stage 9090:=============>                                         (3 + 9) / 12]\n\n[Stage 9090:==================>                                    (4 + 8) / 12]\n\n[Stage 9090:======================>                                (5 + 7) / 12]\n\n[Stage 9090:================================>                      (7 + 5) / 12]\n\n[Stage 9090:====================================>                  (8 + 4) / 12]\n\n[Stage 9092:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9095:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9098:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9101:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9104:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9107:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9110:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9113:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9116:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9119:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9122:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9125:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9128:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9131:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9134:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9137:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9140:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9143:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9146:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9149:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9152:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9155:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9158:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9161:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9164:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9167:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9170:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9173:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9176:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9179:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9182:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9185:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9188:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9191:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9194:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9197:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9200:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9203:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9206:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9209:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9212:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9215:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9218:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9221:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9224:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9227:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9230:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9233:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9236:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9239:>                                                       (0 + 1) / 1]\n\n                                                                                \n\n[Stage 9242:>                                                       (0 + 1) / 1]\n\n                                                                                \nTrain time:615.156226\nPredict time:0.106366\n23/05/12 09:32:42 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n23/05/12 09:32:42 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n\n[Stage 9243:>                                                     (0 + 12) / 12]\n\n[Stage 9243:====>                                                 (1 + 11) / 12]\n\n[Stage 9243:=========>                                            (2 + 10) / 12]\n\n[Stage 9243:=============>                                         (3 + 9) / 12]\n\n[Stage 9243:==================>                                    (4 + 8) / 12]\n\n[Stage 9243:======================>                                (5 + 7) / 12]\n\n[Stage 9243:================================>                      (7 + 5) / 12]\n\n                                                                                \n\n[Stage 9244:>                                                     (0 + 12) / 12]\n\n[Stage 9244:=========>                                            (2 + 10) / 12]\n\n[Stage 9244:=============>                                         (3 + 9) / 12]\n\n[Stage 9244:======================>                                (5 + 7) / 12]\n\n[Stage 9244:================================>                      (7 + 5) / 12]\n\n[Stage 9246:>                                                       (0 + 1) / 1]\n\n                                                                                \n23/05/12 09:33:13 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n23/05/12 09:33:13 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n\n[Stage 9259:>                                                     (0 + 12) / 12]\n\n[Stage 9259:====>                                                 (1 + 11) / 12]\n\n[Stage 9259:=========>                                            (2 + 10) / 12]\n\n[Stage 9259:=============>                                         (3 + 9) / 12]\n\n[Stage 9259:==================>                                    (4 + 8) / 12]\n\n[Stage 9259:======================>                                (5 + 7) / 12]\n\n[Stage 9259:===========================>                           (6 + 6) / 12]\n\n[Stage 9259:================================>                      (7 + 5) / 12]\n\n                                                                                \n\n[Stage 9260:>                                                     (0 + 12) / 12]\n\n[Stage 9260:====>                                                 (1 + 11) / 12]\n\n[Stage 9260:=========>                                            (2 + 10) / 12]\n\n[Stage 9260:=============>                                         (3 + 9) / 12]\n\n[Stage 9260:==================>                                    (4 + 8) / 12]\n\n[Stage 9260:======================>                                (5 + 7) / 12]\n\n[Stage 9260:===========================>                           (6 + 6) / 12]\n\n[Stage 9260:================================>                      (7 + 5) / 12]\n\n[Stage 9262:>                                                       (0 + 1) / 1]\n\n                                                                                \nEval results RP curve train_test: 0.639384823587 / 0.62703633608\n"}]},"apps":[],"jobName":"paragraph_1683851769834_-1488784976","id":"20230512-003609_1905415830","dateCreated":"2023-05-12T00:36:09+0000","dateStarted":"2023-05-12T09:22:27+0000","dateFinished":"2023-05-12T09:34:01+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:282"},{"text":"test_data_out=model_svc.transform(test_data)\n\nscored = test_data_out.filter(test_data_out.label  == test_data_out.prediction).count()\ncount = test_data_out.count()\nfloat(scored) / float(count)","user":"anonymous","dateUpdated":"2023-05-12T07:39:00+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python","tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"23/05/12 07:43:48 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n23/05/12 07:43:48 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n\n[Stage 8109:>                                                     (0 + 12) / 12]\n\n[Stage 8109:====>                                                 (1 + 11) / 12]\n\n[Stage 8109:=========>                                            (2 + 10) / 12]\n\n[Stage 8109:=============>                                         (3 + 9) / 12]\n\n[Stage 8109:==================>                                    (4 + 8) / 12]\n\n[Stage 8109:======================>                                (5 + 7) / 12]\n\n[Stage 8109:================================>                      (7 + 5) / 12]\n\n                                                                                \n\n[Stage 8110:>                                                     (0 + 12) / 12]\n\n[Stage 8110:====>                                                 (1 + 11) / 12]\n\n[Stage 8110:=========>                                            (2 + 10) / 12]\n\n[Stage 8110:=============>                                         (3 + 9) / 12]\n\n[Stage 8110:==================>                                    (4 + 8) / 12]\n\n[Stage 8110:======================>                                (5 + 7) / 12]\n\n[Stage 8110:================================>                      (7 + 5) / 12]\n\n[Stage 8110:====================================>                  (8 + 4) / 12]\n\n[Stage 8112:>                                                       (0 + 1) / 1]\n\n                                                                                \n23/05/12 07:44:18 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n\n[Stage 8113:>                                                     (0 + 12) / 12]\n\n[Stage 8113:====>                                                 (1 + 11) / 12]\n\n[Stage 8113:=========>                                            (2 + 10) / 12]\n\n[Stage 8113:=============>                                         (3 + 9) / 12]\n\n[Stage 8113:==================>                                    (4 + 8) / 12]\n\n[Stage 8113:===========================>                           (6 + 6) / 12]\n\n[Stage 8113:================================>                      (7 + 5) / 12]\n\n                                                                                \n0.6295553138807402\n"}]},"apps":[],"jobName":"paragraph_1683836859549_214724831","id":"20230511-202739_485524388","dateCreated":"2023-05-11T20:27:39+0000","dateStarted":"2023-05-12T07:43:30+0000","dateFinished":"2023-05-12T07:44:31+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:283"},{"text":"","user":"anonymous","dateUpdated":"2023-05-12T07:39:00+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"0.6317183480679168\n"}]},"apps":[],"jobName":"paragraph_1683851456086_825262952","id":"20230512-003056_1262683762","dateCreated":"2023-05-12T00:30:56+0000","dateStarted":"2023-05-12T00:31:31+0000","dateFinished":"2023-05-12T00:31:31+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:284"},{"text":"#================saving the test predictions==================\nfor model in zip(\n        [model_gbt, model_svc],\n        [\"gbc\", \"svc\"]\n    ):\n    test_data_out=model[0].transform(test_data)\n    test_data_out.coalesce(1)\\\n        .select(\"tstamp\",'mid_price','label','prediction')\\\n        .write\\\n        .mode(\"overwrite\")\\\n        .format(\"csv\")\\\n        .option(\"sep\", \",\")\\\n        .option(\"header\",\"true\")\\\n        .csv(\"/project/output/predictions_{}\".format(model[1]))\n    model[0].save(\"/project/models/model_{}\".format(model[1]))","user":"anonymous","dateUpdated":"2023-05-12T12:56:14+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python","tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"               23/05/12 12:56:14 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n23/05/12 12:56:14 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n\n[Stage 9766:>                                                     (0 + 12) / 12]\n\n[Stage 9766:====>                                                 (1 + 11) / 12]\n\n[Stage 9766:=========>                                            (2 + 10) / 12]\n\n[Stage 9766:=============>                                         (3 + 9) / 12]\n\n[Stage 9766:==================>                                    (4 + 8) / 12]\n\n[Stage 9766:======================>                                (5 + 7) / 12]\n\n[Stage 9766:===========================>                           (6 + 6) / 12]\n\n[Stage 9766:================================>                      (7 + 5) / 12]\n\n[Stage 9766:=============================================>        (10 + 2) / 12]\n\n                                                                                \n\n[Stage 9767:>                                                     (0 + 12) / 12]\n\n[Stage 9767:====>                                                 (1 + 11) / 12]\n\n[Stage 9767:=========>                                            (2 + 10) / 12]\n\n[Stage 9767:=============>                                         (3 + 9) / 12]\n\n[Stage 9767:==================>                                    (4 + 8) / 12]\n\n[Stage 9767:======================>                                (5 + 7) / 12]\n\n[Stage 9767:===========================>                           (6 + 6) / 12]\n\n[Stage 9767:================================>                      (7 + 5) / 12]\n\n[Stage 9769:>                                                       (0 + 1) / 1]\n\n                                                                                \n23/05/12 12:56:43 WARN hadoop.MemoryManager: Total allocation exceeds 95.00% (961,780,110 bytes) of heap memory\nScaling row group sizes to 89.57% for 8 writers\n23/05/12 12:56:43 WARN hadoop.MemoryManager: Total allocation exceeds 95.00% (961,780,110 bytes) of heap memory\nScaling row group sizes to 79.62% for 9 writers\n23/05/12 12:56:43 WARN hadoop.MemoryManager: Total allocation exceeds 95.00% (961,780,110 bytes) of heap memory\nScaling row group sizes to 71.66% for 10 writers\n23/05/12 12:56:43 WARN hadoop.MemoryManager: Total allocation exceeds 95.00% (961,780,110 bytes) of heap memory\nScaling row group sizes to 65.14% for 11 writers\n23/05/12 12:56:43 WARN hadoop.MemoryManager: Total allocation exceeds 95.00% (961,780,110 bytes) of heap memory\nScaling row group sizes to 59.72% for 12 writers\n23/05/12 12:56:43 WARN hadoop.MemoryManager: Total allocation exceeds 95.00% (961,780,110 bytes) of heap memory\nScaling row group sizes to 65.14% for 11 writers\n23/05/12 12:56:43 WARN hadoop.MemoryManager: Total allocation exceeds 95.00% (961,780,110 bytes) of heap memory\nScaling row group sizes to 71.66% for 10 writers\n23/05/12 12:56:43 WARN hadoop.MemoryManager: Total allocation exceeds 95.00% (961,780,110 bytes) of heap memory\nScaling row group sizes to 79.62% for 9 writers\n23/05/12 12:56:43 WARN hadoop.MemoryManager: Total allocation exceeds 95.00% (961,780,110 bytes) of heap memory\nScaling row group sizes to 89.57% for 8 writers\n23/05/12 12:56:44 WARN hadoop.MemoryManager: Total allocation exceeds 95.00% (961,780,110 bytes) of heap memory\nScaling row group sizes to 89.57% for 8 writers\n23/05/12 12:56:44 WARN hadoop.MemoryManager: Total allocation exceeds 95.00% (961,780,110 bytes) of heap memory\nScaling row group sizes to 79.62% for 9 writers\n23/05/12 12:56:44 WARN hadoop.MemoryManager: Total allocation exceeds 95.00% (961,780,110 bytes) of heap memory\nScaling row group sizes to 71.66% for 10 writers\n23/05/12 12:56:44 WARN hadoop.MemoryManager: Total allocation exceeds 95.00% (961,780,110 bytes) of heap memory\nScaling row group sizes to 65.14% for 11 writers\n23/05/12 12:56:44 WARN hadoop.MemoryManager: Total allocation exceeds 95.00% (961,780,110 bytes) of heap memory\nScaling row group sizes to 59.72% for 12 writers\n23/05/12 12:56:44 WARN hadoop.MemoryManager: Total allocation exceeds 95.00% (961,780,110 bytes) of heap memory\nScaling row group sizes to 65.14% for 11 writers\n23/05/12 12:56:44 WARN hadoop.MemoryManager: Total allocation exceeds 95.00% (961,780,110 bytes) of heap memory\nScaling row group sizes to 71.66% for 10 writers\n23/05/12 12:56:44 WARN hadoop.MemoryManager: Total allocation exceeds 95.00% (961,780,110 bytes) of heap memory\nScaling row group sizes to 79.62% for 9 writers\n23/05/12 12:56:44 WARN hadoop.MemoryManager: Total allocation exceeds 95.00% (961,780,110 bytes) of heap memory\nScaling row group sizes to 89.57% for 8 writers\n23/05/12 12:56:44 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n23/05/12 12:56:44 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n\n[Stage 9773:>                                                     (0 + 12) / 12]\n\n[Stage 9773:====>                                                 (1 + 11) / 12]\n\n[Stage 9773:=========>                                            (2 + 10) / 12]\n\n[Stage 9773:=============>                                         (3 + 9) / 12]\n\n[Stage 9773:==================>                                    (4 + 8) / 12]\n\n[Stage 9773:======================>                                (5 + 7) / 12]\n\n[Stage 9773:================================>                      (7 + 5) / 12]\n\n[Stage 9773:=================================================>    (11 + 1) / 12]\n\n                                                                                \n\n[Stage 9774:>                                                     (0 + 12) / 12]\n\n[Stage 9774:====>                                                 (1 + 11) / 12]\n\n[Stage 9774:=========>                                            (2 + 10) / 12]\n\n[Stage 9774:=============>                                         (3 + 9) / 12]\n\n[Stage 9774:==================>                                    (4 + 8) / 12]\n\n[Stage 9774:======================>                                (5 + 7) / 12]\n\n[Stage 9774:===========================>                           (6 + 6) / 12]\n\n[Stage 9774:================================>                      (7 + 5) / 12]\n\n[Stage 9776:>                                                       (0 + 1) / 1]\n23/05/12 12:57:13 ERROR util.Utils: Aborting task\norg.apache.spark.SparkException: Failed to execute user defined function(ClassificationModel$$Lambda$4050/1486433685: (struct<type:tinyint,size:int,indices:array<int>,values:array<double>>) => struct<type:tinyint,size:int,indices:array<int>,values:array<double>>)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:488)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:277)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:286)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:463)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:466)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.IllegalArgumentException: requirement failed: BLAS.dot(x: Vector, y:Vector) was given Vectors with non-matching sizes: x.size = 48, y.size = 12\n\tat scala.Predef$.require(Predef.scala:281)\n\tat org.apache.spark.ml.linalg.BLAS$.dot(BLAS.scala:115)\n\tat org.apache.spark.ml.classification.LinearSVCModel.$anonfun$margin$1(LinearSVC.scala:301)\n\tat org.apache.spark.ml.classification.LinearSVCModel.$anonfun$margin$1$adapted(LinearSVC.scala:300)\n\tat org.apache.spark.ml.classification.LinearSVCModel.predictRaw(LinearSVC.scala:310)\n\tat org.apache.spark.ml.classification.LinearSVCModel.predictRaw(LinearSVC.scala:284)\n\tat org.apache.spark.ml.classification.ClassificationModel.$anonfun$transform$1(Classifier.scala:212)\n\t 16 more\n23/05/12 12:57:13 ERROR datasources.FileFormatWriter: Job job_20230512125656927162536381352852_9776 aborted.\n23/05/12 12:57:13 ERROR executor.Executor: Exception in task 0.0 in stage 9776.0 (TID 30644)\norg.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:296)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:463)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:466)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Failed to execute user defined function(ClassificationModel$$Lambda$4050/1486433685: (struct<type:tinyint,size:int,indices:array<int>,values:array<double>>) => struct<type:tinyint,size:int,indices:array<int>,values:array<double>>)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:488)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:277)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:286)\n\t 9 more\nCaused by: java.lang.IllegalArgumentException: requirement failed: BLAS.dot(x: Vector, y:Vector) was given Vectors with non-matching sizes: x.size = 48, y.size = 12\n\tat scala.Predef$.require(Predef.scala:281)\n\tat org.apache.spark.ml.linalg.BLAS$.dot(BLAS.scala:115)\n\tat org.apache.spark.ml.classification.LinearSVCModel.$anonfun$margin$1(LinearSVC.scala:301)\n\tat org.apache.spark.ml.classification.LinearSVCModel.$anonfun$margin$1$adapted(LinearSVC.scala:300)\n\tat org.apache.spark.ml.classification.LinearSVCModel.predictRaw(LinearSVC.scala:310)\n\tat org.apache.spark.ml.classification.LinearSVCModel.predictRaw(LinearSVC.scala:284)\n\tat org.apache.spark.ml.classification.ClassificationModel.$anonfun$transform$1(Classifier.scala:212)\n\t 16 more\n23/05/12 12:57:13 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 9776.0 (TID 30644, sandbox-hdp.hortonworks.com, executor driver): org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:296)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:463)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:466)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Failed to execute user defined function(ClassificationModel$$Lambda$4050/1486433685: (struct<type:tinyint,size:int,indices:array<int>,values:array<double>>) => struct<type:tinyint,size:int,indices:array<int>,values:array<double>>)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:488)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:277)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:286)\n\t 9 more\nCaused by: java.lang.IllegalArgumentException: requirement failed: BLAS.dot(x: Vector, y:Vector) was given Vectors with non-matching sizes: x.size = 48, y.size = 12\n\tat scala.Predef$.require(Predef.scala:281)\n\tat org.apache.spark.ml.linalg.BLAS$.dot(BLAS.scala:115)\n\tat org.apache.spark.ml.classification.LinearSVCModel.$anonfun$margin$1(LinearSVC.scala:301)\n\tat org.apache.spark.ml.classification.LinearSVCModel.$anonfun$margin$1$adapted(LinearSVC.scala:300)\n\tat org.apache.spark.ml.classification.LinearSVCModel.predictRaw(LinearSVC.scala:310)\n\tat org.apache.spark.ml.classification.LinearSVCModel.predictRaw(LinearSVC.scala:284)\n\tat org.apache.spark.ml.classification.ClassificationModel.$anonfun$transform$1(Classifier.scala:212)\n\t 16 more\n\n23/05/12 12:57:13 ERROR scheduler.TaskSetManager: Task 0 in stage 9776.0 failed 1 times; aborting job\n23/05/12 12:57:13 ERROR datasources.FileFormatWriter: Aborting job dfb060e0-eecf-4c84-bfdf-d1ce26b57d49.\norg.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 9776.0 failed 1 times, most recent failure: Lost task 0.0 in stage 9776.0 (TID 30644, sandbox-hdp.hortonworks.com, executor driver): org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:296)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:463)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:466)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Failed to execute user defined function(ClassificationModel$$Lambda$4050/1486433685: (struct<type:tinyint,size:int,indices:array<int>,values:array<double>>) => struct<type:tinyint,size:int,indices:array<int>,values:array<double>>)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:488)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:277)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:286)\n\t 9 more\nCaused by: java.lang.IllegalArgumentException: requirement failed: BLAS.dot(x: Vector, y:Vector) was given Vectors with non-matching sizes: x.size = 48, y.size = 12\n\tat scala.Predef$.require(Predef.scala:281)\n\tat org.apache.spark.ml.linalg.BLAS$.dot(BLAS.scala:115)\n\tat org.apache.spark.ml.classification.LinearSVCModel.$anonfun$margin$1(LinearSVC.scala:301)\n\tat org.apache.spark.ml.classification.LinearSVCModel.$anonfun$margin$1$adapted(LinearSVC.scala:300)\n\tat org.apache.spark.ml.classification.LinearSVCModel.predictRaw(LinearSVC.scala:310)\n\tat org.apache.spark.ml.classification.LinearSVCModel.predictRaw(LinearSVC.scala:284)\n\tat org.apache.spark.ml.classification.ClassificationModel.$anonfun$transform$1(Classifier.scala:212)\n\t 16 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2008)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2007)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2007)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:973)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:973)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:973)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2239)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2188)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2177)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:775)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:200)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:178)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:127)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:126)\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:962)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:767)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:962)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:414)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:398)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:287)\n\tat org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:952)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:296)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:463)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:466)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t 1 more\nCaused by: org.apache.spark.SparkException: Failed to execute user defined function(ClassificationModel$$Lambda$4050/1486433685: (struct<type:tinyint,size:int,indices:array<int>,values:array<double>>) => struct<type:tinyint,size:int,indices:array<int>,values:array<double>>)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:488)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:277)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:286)\n\t 9 more\nCaused by: java.lang.IllegalArgumentException: requirement failed: BLAS.dot(x: Vector, y:Vector) was given Vectors with non-matching sizes: x.size = 48, y.size = 12\n\tat scala.Predef$.require(Predef.scala:281)\n\tat org.apache.spark.ml.linalg.BLAS$.dot(BLAS.scala:115)\n\tat org.apache.spark.ml.classification.LinearSVCModel.$anonfun$margin$1(LinearSVC.scala:301)\n\tat org.apache.spark.ml.classification.LinearSVCModel.$anonfun$margin$1$adapted(LinearSVC.scala:300)\n\tat org.apache.spark.ml.classification.LinearSVCModel.predictRaw(LinearSVC.scala:310)\n\tat org.apache.spark.ml.classification.LinearSVCModel.predictRaw(LinearSVC.scala:284)\n\tat org.apache.spark.ml.classification.ClassificationModel.$anonfun$transform$1(Classifier.scala:212)\n\t 16 more\nTraceback (most recent call last):\n  File \"<stdin>\", line 14, in <module>\n  File \"/usr/lib/python2.7/site-packages/pyspark/sql/readwriter.py\", line 1030, in csv\n    self._jwrite.csv(path)\n  File \"/usr/lib/python2.7/site-packages/py4j/java_gateway.py\", line 1305, in __call__\n    answer, self.gateway_client, self.target_id, self.name)\n  File \"/usr/lib/python2.7/site-packages/pyspark/sql/utils.py\", line 128, in deco\n    return f(*a, **kw)\n  File \"/usr/lib/python2.7/site-packages/py4j/protocol.py\", line 328, in get_return_value\n    format(target_id, \".\", name), value)\npy4j.protocol.Py4JJavaError: An error occurred while calling o13269.csv.\n: org.apache.spark.SparkException: Job aborted.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:231)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:178)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:127)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:126)\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:962)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:767)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:962)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:414)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:398)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:287)\n\tat org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:952)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 9776.0 failed 1 times, most recent failure: Lost task 0.0 in stage 9776.0 (TID 30644, sandbox-hdp.hortonworks.com, executor driver): org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:296)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:463)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:466)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Failed to execute user defined function(ClassificationModel$$Lambda$4050/1486433685: (struct<type:tinyint,size:int,indices:array<int>,values:array<double>>) => struct<type:tinyint,size:int,indices:array<int>,values:array<double>>)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:488)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:277)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:286)\n\t 9 more\nCaused by: java.lang.IllegalArgumentException: requirement failed: BLAS.dot(x: Vector, y:Vector) was given Vectors with non-matching sizes: x.size = 48, y.size = 12\n\tat scala.Predef$.require(Predef.scala:281)\n\tat org.apache.spark.ml.linalg.BLAS$.dot(BLAS.scala:115)\n\tat org.apache.spark.ml.classification.LinearSVCModel.$anonfun$margin$1(LinearSVC.scala:301)\n\tat org.apache.spark.ml.classification.LinearSVCModel.$anonfun$margin$1$adapted(LinearSVC.scala:300)\n\tat org.apache.spark.ml.classification.LinearSVCModel.predictRaw(LinearSVC.scala:310)\n\tat org.apache.spark.ml.classification.LinearSVCModel.predictRaw(LinearSVC.scala:284)\n\tat org.apache.spark.ml.classification.ClassificationModel.$anonfun$transform$1(Classifier.scala:212)\n\t 16 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2008)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2007)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2007)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:973)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:973)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:973)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2239)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2188)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2177)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:775)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:200)\n\t 33 more\nCaused by: org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:296)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:463)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:466)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t 1 more\nCaused by: org.apache.spark.SparkException: Failed to execute user defined function(ClassificationModel$$Lambda$4050/1486433685: (struct<type:tinyint,size:int,indices:array<int>,values:array<double>>) => struct<type:tinyint,size:int,indices:array<int>,values:array<double>>)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:488)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:277)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:286)\n\t 9 more\nCaused by: java.lang.IllegalArgumentException: requirement failed: BLAS.dot(x: Vector, y:Vector) was given Vectors with non-matching sizes: x.size = 48, y.size = 12\n\tat scala.Predef$.require(Predef.scala:281)\n\tat org.apache.spark.ml.linalg.BLAS$.dot(BLAS.scala:115)\n\tat org.apache.spark.ml.classification.LinearSVCModel.$anonfun$margin$1(LinearSVC.scala:301)\n\tat org.apache.spark.ml.classification.LinearSVCModel.$anonfun$margin$1$adapted(LinearSVC.scala:300)\n\tat org.apache.spark.ml.classification.LinearSVCModel.predictRaw(LinearSVC.scala:310)\n\tat org.apache.spark.ml.classification.LinearSVCModel.predictRaw(LinearSVC.scala:284)\n\tat org.apache.spark.ml.classification.ClassificationModel.$anonfun$transform$1(Classifier.scala:212)\n\t 16 more\n\n"}]},"apps":[],"jobName":"paragraph_1683830805929_-2068428740","id":"20230511-184645_435661285","dateCreated":"2023-05-11T18:46:45+0000","dateStarted":"2023-05-12T12:56:14+0000","dateFinished":"2023-05-12T12:57:14+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:285"},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1683878344300_-1976651506","id":"20230512-075904_918307009","dateCreated":"2023-05-12T07:59:04+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:286"}],"name":"pain","id":"2HYFWW4X4","angularObjects":{"2HZ141EKG:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}